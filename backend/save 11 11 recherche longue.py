from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from openai import OpenAI
import os, signal, json, re, requests, urllib.parse, time
from datetime import datetime
from dotenv import load_dotenv

# ======================================================
# ‚öôÔ∏è Feature flags ‚Äî activables/d√©sactivables sans casser
# ======================================================
ENABLE_SYNTHESIS = True       # Ajoute une synth√®se narrative lisible
ENABLE_CONTEXT_BOX = True     # Ajoute un √©clairage contextuel court + web enrichi
ENABLE_TRANSPARENCY = True    # Ajoute mentions "exp√©rimental" et tronquage
ENABLE_URL_EXTRACT = True     # Active Trafilatura (si URL fournie)

# ======================================================
# Flask setup
# ======================================================
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}}, supports_credentials=True)

# ======================================================
# OpenAI client
# ======================================================
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ======================================================
# Timeout (Render/Replit safety)
# ======================================================
def _timeout_handler(signum, frame):
    raise TimeoutError("Analyse trop longue (timeout Render).")
signal.signal(signal.SIGALRM, _timeout_handler)

# ======================================================
# Helpers
# ======================================================
def color_for(score: int) -> str:
    if score is None: return "‚ö™"
    if score >= 70: return "üü¢"
    if score >= 40: return "üü°"
    return "üî¥"

# ======================================================
# üåê Recherche Google CSE (Programmable Search API)
# ======================================================
ALLOWED_SITES = [
    "reuters.com", "apnews.com", "bbc.com",
    "lemonde.fr", "francetvinfo.fr",
    "lefigaro.fr", "liberation.fr", "leparisien.fr"
]

def search_web_results(queries, per_query=5, pause=0.5):
    """Recherche Google CSE (Programmable Search API) sur plusieurs entit√©s ou requ√™tes."""
    api_key = os.getenv("GOOGLE_CSE_API_KEY")
    cx = os.getenv("GOOGLE_CSE_CX")
    if not api_key or not cx:
        print("‚ö†Ô∏è GOOGLE_CSE_API_KEY ou GOOGLE_CSE_CX manquant ‚Äî recherche d√©sactiv√©e.")
        return []

    all_hits = []
    seen = set()
    for q in queries:
        site_filter = " OR ".join([f"site:{s}" for s in ALLOWED_SITES])
        full_q = f"{q} ({site_filter})"
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": api_key,
            "cx": cx,
            "q": full_q,
            "num": per_query,
            "hl": "fr",
            "lr": "lang_fr",
            "safe": "off"
        }
        try:
            r = requests.get(url, params=params, timeout=10)
            if r.status_code != 200:
                print("‚ö†Ô∏è Erreur Google CSE:", r.status_code, r.text[:200])
                continue
            data = r.json()
            results = []
            for item in data.get("items", []) or []:
                link = item.get("link")
                if link and link not in seen:
                    seen.add(link)
                    results.append({
                        "titre": item.get("title"),
                        "snippet": item.get("snippet"),
                        "url": link
                    })
            if results:
                all_hits.append({"entit√©": q, "sources": results})
            time.sleep(pause)
        except Exception as e:
            print("‚ö†Ô∏è Erreur recherche Google:", e)
            continue
    return all_hits









# ======================================================
# üß© Commentaire web
# ======================================================

def formate_commentaires_web(web_info):
    """Cr√©e un commentaire journalistique √† partir des faits manquants, contradictions et divergences."""
    commentaires = []

    # Contradictions : ton ‚Äúfact-check‚Äù nuanc√©
    for c in web_info.get("contradictions", []) or []:
        if isinstance(c, dict):
            commentaires.append(
                f"Selon {c.get('source', 'une source')}, {c.get('correction_ou_nuance', '').strip()} "
                f"ce qui nuance l‚Äôaffirmation du texte ({c.get('affirmation_du_texte', '').strip()})."
            )
        elif isinstance(c, str):
            commentaires.append(c.strip())

    # Faits manquants : ton ‚Äúanalyse critique‚Äù
    for f in web_info.get("faits_manquants", []) or []:
        if isinstance(f, dict):
            commentaires.append(
                f"Le texte n‚Äô√©voque pas {f.get('description', '').strip()} "
                f"(mentionn√© par {f.get('source', 'une autre source')}). "
                f"{f.get('explication', '').strip()}"
            )

    # Divergences de cadrage : ton ‚Äúanalyse narrative‚Äù
    for d in web_info.get("divergences_de_cadrage", []) or []:
        if isinstance(d, dict):
            commentaires.append(
                f"Le cadrage diff√®re : {d.get('resume', '').strip()} "
                f"{d.get('impact', '').strip()}"
            )

    # Synth√®se finale (courte)
    synth = web_info.get("synthese", "")
    if synth:
        commentaires.append(synth.strip())

    return " ".join(commentaires[:5]) or "Aucun √©cart majeur entre le texte et les sources consult√©es."

# ======================================================
# üß© PIPELINE EXP√âRIMENTAL ‚Äî version structur√©e et robuste
# ======================================================

def extract_global_message(client, text):
    """√âtape 0 ‚Äî Analyse le message global et l‚Äôimpression que retient un lecteur moyen."""
    prompt = f"""
    Lis ce texte comme le ferait un lecteur moyen (non expert).
    D√©cris :
    1Ô∏è‚É£ Ce que le lecteur retient (message global implicite ou explicite)
    2Ô∏è‚É£ Le ton g√©n√©ral (neutre, √©logieux, alarmiste, ironique, critique‚Ä¶)
    3Ô∏è‚É£ L‚Äôintention per√ßue (informer, convaincre, valoriser, critiquer, d√©samorcer, dramatiser‚Ä¶)
    4Ô∏è‚É£ Le niveau de confiance per√ßu (fort, moyen, faible)
    5Ô∏è‚É£ L‚Äôimpression √©motionnelle laiss√©e (apaisante, persuasive, tendue‚Ä¶)

    R√©ponds uniquement en JSON :
    {{
      "message_global": "<ce qu‚Äôun lecteur retient>",
      "ton_general": "<neutre|positif|critique|alarmiste|ironique|√©logieux>",
      "intention_per√ßue": "<informer|convaincre|valoriser|critiquer|d√©samorcer|dramatiser>",
      "niveau_de_confiance": "<fort|moyen|faible>",
      "resume_emotionnel": "<description br√®ve>"
    }}

    Texte :
    {text[:4000]}
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un analyste cognitif sp√©cialis√© dans la r√©ception m√©diatique. Tu d√©cris ce que le lecteur moyen retient d‚Äôun texte."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.35
        )
        raw = resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(m.group(0)) if m else {}
    except Exception as e:
        print("‚ö†Ô∏è extract_global_message error:", e)
        return {}


def summarize_text(client, text):
    """√âtape 1 ‚Äî R√©sume le texte et s√©pare faits / opinions avec ancrage (citations courtes)."""
    prompt = f"""
    R√©sume le texte suivant de mani√®re neutre, puis liste :
    - Les faits (affirmations v√©rifiables),
    - Les opinions (jugements, interpr√©tations).

    Pour chaque fait, joins un court extrait du texte (‚â§15 mots) pour ancrer la preuve.

    R√©ponds **uniquement** en JSON :
    {{
      "resume": "<r√©sum√© g√©n√©ral>",
      "faits": [{{"texte": "<fait>", "extrait_article": "<citation courte>"}}],
      "opinions": ["<opinion>", ...]
    }}

    Texte :
    {text[:4000]}
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un journaliste neutre. S√©pare faits et opinions avec extraits pr√©cis."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        raw = resp.choices[0].message.content.strip()
        match = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(match.group(0)) if match else {"resume": "", "faits": [], "opinions": []}
    except Exception as e:
        print("‚ö†Ô∏è summarize_text error:", e)
        return {"resume": "", "faits": [], "opinions": []}


def consolidate_web_facts(client, web_hits):
    """√âtape 2 ‚Äî Transforme les r√©sultats web en faits v√©rifiables (avec extrait source)."""
    prompt = f"""
    √Ä partir de ces extraits web, liste uniquement les faits v√©rifiables et neutres (√©v√©nements, chiffres, d√©cisions, citations importantes).
    Pour chaque fait, donne la source et un court extrait (‚â§15 mots).

    R√©ponds en JSON :
    {{
      "faits_web": [{{"fait": "...", "source": "...", "url": "...", "extrait_source": "..."}}]
    }}

    Extraits web :
    {json.dumps(web_hits, ensure_ascii=False, indent=2)}
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un fact-checker. Tu identifies uniquement les faits neutres et sourc√©s."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        raw = resp.choices[0].message.content.strip()
        match = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(match.group(0)) if match else {"faits_web": []}
    except Exception as e:
        print("‚ö†Ô∏è consolidate_web_facts error:", e)
        return {"faits_web": []}


def compare_text_with_web(client, summary, web_facts):
    """√âtape 3 ‚Äî Compare le texte et les faits web : omissions, contradictions, cadrages."""
    prompt = f"""
    Compare les faits du texte avec ceux des sources web.
    Identifie :
    - les faits manquants (√©l√©ments absents du texte mais confirm√©s ailleurs),
    - les contradictions (texte vs sources),
    - les divergences de cadrage (diff√©rences d‚Äôangle narratif).

    Pour chaque entr√©e, donne un extrait du texte et un extrait de source pour appuyer l‚Äôanalyse.

    R√©ponds uniquement en JSON :
    {{
      "faits_manquants": [{{"manque": "...", "pourquoi_cela_compte": "...", "source": "...", "url": "...", "extrait_source": "..."}}],
      "contradictions": [{{"affirmation_du_texte": "...", "contrepoint": "...", "source": "...", "url": "...", "extrait_source": "..."}}],
      "divergences_de_cadrage": [{{"resume": "...", "impact": "..."}}],
      "impact": "<faible|moyen|fort>"
    }}

    FAITS DU TEXTE :
    {json.dumps(summary, ensure_ascii=False, indent=2)}

    FAITS DU WEB :
    {json.dumps(web_facts, ensure_ascii=False, indent=2)}
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Tu es un analyste comparatif entre texte et sources web."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        raw = resp.choices[0].message.content.strip()
        match = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(match.group(0)) if match else {"faits_manquants": [], "contradictions": [], "divergences_de_cadrage": [], "impact": "faible"}
    except Exception as e:
        print("‚ö†Ô∏è compare_text_with_web error:", e)
        return {"faits_manquants": [], "contradictions": [], "divergences_de_cadrage": [], "impact": "faible"}


def evaluate_text(client, summary, web_facts, diffs, global_msg=None):
    """
    √âtape 4 ‚Äî √âvalue le texte sur 4 axes avec p√©dagogie.
    Chaque sous-score est concret, illustr√© et explique l‚Äôeffet sur le lecteur.
    """
    msg_context = (global_msg or {}).get("message_global", "")

    rubric = {
    "justesse": {
        "0":   "Affirmations fausses ou trompeuses.",
        "25":  "Plusieurs impr√©cisions notables.",
        "50":  "Faits globalement exacts mais simplifi√©s.",
        "75":  "Faits exacts, rares impr√©cisions mineures.",
        "100": "Faits parfaitement justes et sourc√©s."
    },
    "completude": {
        "0":   "Omissions critiques changeant compl√®tement le sens.",
        "25":  "Omissions majeures qui biaisent fortement la compr√©hension.",
        "50":  "Certains points manquent et orientent partiellement la lecture.",
        "75":  "Informations bien couvertes, quelques absences secondaires.",
        "100": "Texte tr√®s complet, √©quilibre des points de vue."
    },
    "ton": {
        "0":   "Langage clairement orient√© ou affectif.",
        "25":  "Vocabulaire influen√ßant la perception du lecteur.",
        "50":  "Ton neutre mais l√©g√®res orientations lexicales.",
        "75":  "Ton factuel et mesur√©.",
        "100": "Neutralit√© exemplaire, vocabulaire sobre."
    },
    "sophismes": {
        "0":   "Raisonnement illogique ou manipulateur.",
        "25":  "Causalit√©s fausses ou raccourcis notables.",
        "50":  "Quelques simplifications qui alt√®rent la rigueur.",
        "75":  "Raisonnement globalement solide.",
        "100": "Logique rigoureuse, distinctions claires entre faits et interpr√©tations."
    }
    }

    prompt = f"""
    Tu es **De Facto**, un journaliste-analyste p√©dagogue.
    Pour chaque axe, tu dois √©crire comme si tu expliquais ton √©valuation √† un lecteur non expert.
    Chaque sous-note doit r√©pondre √† trois questions :
      1Ô∏è‚É£ Qu‚Äôest-ce que le texte dit ou montre ? (observation concr√®te)
      2Ô∏è‚É£ Peux-tu donner un exemple pr√©cis du texte ?
      3Ô∏è‚É£ Qu‚Äôest-ce que √ßa fait au lecteur ? (effet sur sa compr√©hension ou perception)

    ‚öôÔ∏è Structure attendue pour chaque axe :
    {{
      "note": <0|25|50|75|100>,
      "anchor_matched": <0|25|50|75|100>,
      "severity_for_reader": "<faible|moyenne|√©lev√©e>",
      "justification": "R√©daction p√©dagogique expliquant le constat + exemple + effet sur le lecteur.",
      "citation": "Extrait court illustratif."
    }}

    ‚öñÔ∏è Bar√®me utilis√© :
    {json.dumps(rubric, ensure_ascii=False, indent=2)}

    Contexte per√ßu par le lecteur : "{msg_context}"

    Mati√®res disponibles :
    - R√©sum√© et faits du texte : {json.dumps(summary, ensure_ascii=False, indent=2)}
    - Faits web : {json.dumps(web_facts, ensure_ascii=False, indent=2)}
    - √âcarts d√©tect√©s : {json.dumps(diffs, ensure_ascii=False, indent=2)}

    ‚ö†Ô∏è R√®gles :
    - Sois concret, clair et explicatif.
    - Ne dis pas ‚Äúle texte est biais√©‚Äù mais ‚Äúle texte donne l‚Äôimpression que‚Ä¶‚Äù.
    - Donne toujours un exemple de formulation ou d‚Äôextrait.
    - Explique √† chaque fois pourquoi cela compte pour le lecteur.
    - √âvite le jargon et les phrases vagues (‚Äúle contexte est tendu‚Äù sans exemple).
    - R√©ponds uniquement en JSON, avec la structure :
      {{
    "axes": {{
      "fond": {{
        "justesse": {{...}},
        "completude": {{...}}
      }},
      "forme": {{
        "ton": {{...}},
        "sophismes": {{...}}
      }}
    }}
      }}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                "role": "system",
                "content": (
                    "Tu es un journaliste-analyste p√©dagogique, clair et concret. "
                    "Tu illustres chaque constat avec un exemple et expliques son impact sur le lecteur."
                )
            },
                {"role": "user", "content": prompt}
        ],
            temperature=0.25
        )
        raw = resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", raw, re.DOTALL)
        parsed = json.loads(m.group(0)) if m else {"axes": {}}
        return parsed
    except Exception as e:
        print("‚ö†Ô∏è evaluate_text error:", e)
        return {"axes": {}}



def synthesize_from_axes(client, evaluation):
    """
    Synth√®se explicative et p√©dagogique (3 blocs). N'indique jamais de score.
    """
    prompt = f"""
    Tu es un journaliste p√©dagogue. Explique au lecteur non expert, clairement et avec exemples,
    ce qu‚Äôil retient du texte, ce qui manque, et l‚Äôeffet global sur sa compr√©hension.
    
    ‚úçÔ∏è Structure OBLIGATOIRE (3 blocs, 2-4 phrases chacun) :
    1) Ce que le texte dit et fait croire (message retenu + ton + comment c'est amen√©).
       Exemple: ¬´ L‚Äôarticle pr√©sente X comme un choix 'technique' et neutre; le lecteur retient l‚Äôid√©e d‚Äôefficacit√©. ¬ª
    
    2) Ce qui manque / est simplifi√©, et pourquoi √ßa compte (exemples concrets + effet sur ce que croit le lecteur).
       Exemple: ¬´ Le texte ne mentionne pas [critique/contre-exemple]. Sans cela, le lecteur pense √† un consensus. ¬ª
    
    3) Effet global sur la compr√©hension (perception induite et limites).
       Exemple: ¬´ En insistant sur [√©l√©ment] et en √©vitant [contrepoint], l‚Äôarticle donne une impression de stabilit√©, mais gomme les enjeux politiques. ¬ª
    
    ‚ö†Ô∏è Interdits:
    - NE JAMAIS mentionner de chiffres de note ou de score.
    - Pas de jargon. Pas d‚Äôabstractions vagues (¬´ contexte tendu ¬ª) sans exemple.
    
    Mati√®re:
    {json.dumps(evaluation, ensure_ascii=False, indent=2)}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Tu √©cris comme un journaliste-explicateur: clair, concret, avec exemples. Jamais de score."},
                {"role": "user", "content": prompt}
        ],
            temperature=0.35
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        print("‚ö†Ô∏è synthesize_from_axes error:", e)
        return "Synth√®se non disponible."



def compute_global_score(evals_axes, diffs_impact: str, densite_faits: int) -> int:
    """
    Calcule un score global d√©terministe √† partir des notes par axe.
    Pond√©rations: Justesse 0.4, Compl√©tude 0.3, Ton 0.15, Sophismes 0.15.
    Ajustements:
      - Impact 'fort' : -10 si Justesse < 60 ou Compl√©tude < 60
      - Impact 'moyen': -5  si Justesse < 60 ou Compl√©tude < 60
      - Densit√© factuelle: +5 si >60 ; -5 si <30
    Renvoie un entier 0‚Äì100.
    """
    try:
        j = int(evals_axes["fond"]["justesse"]["note"])
        c = int(evals_axes["fond"]["completude"]["note"])
        t = int(evals_axes["forme"]["ton"]["note"])
        s = int(evals_axes["forme"]["sophismes"]["note"])
    except Exception:
        return 50  # fallback s√ªr

    base = (0.4 * j) + (0.3 * c) + (0.15 * t) + (0.15 * s)

    # Impact du manque sur compr√©hension
    impact = (diffs_impact or "faible").lower().strip()
    if (j < 60 or c < 60):
        if impact == "fort":
            base -= 10
        elif impact == "moyen":
            base -= 5

    # Densit√© factuelle (ton ancien r√©glage, mais ici centralis√©)
    if densite_faits > 60:
        base += 5
    elif densite_faits < 30:
        base -= 5

    return max(0, min(100, round(base)))

# ======================================================
# üåç Recherche Web contextuelle (externe √† analyze)
# ======================================================
def web_context_research(text: str):
    """
    √âtape d'enrichissement factuel :
    1) Extrait les entit√©s du texte (personnes, lieux, orga, √©v√©nements)
    2) Recherche des sources fiables (Reuters, AP, BBC, Le Monde, Franceinfo)
    3) Synth√©tise : faits manquants pr√©cis + contradictions + impact + fiabilit√©
    Retour JSON robuste m√™me en cas d'√©chec partiel.
    """
    try:
        # 1Ô∏è‚É£ Extraction d'entit√©s
        ent_prompt = f"""
        Extrait les principales entit√©s nomm√©es (personnes, lieux, organisations, √©v√©nements, lois, chiffres cl√©s)
        du texte suivant :
        {text[:2000]}

        R√©ponds uniquement en JSON : ["entit√©1", "entit√©2", ...]
        """
        ent_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un extracteur d'entit√©s journalistiques (NER)."},
                {"role": "user", "content": ent_prompt}
            ],
            temperature=0
        )
        raw_entities = ent_resp.choices[0].message.content.strip()
        m = re.search(r"\[.*\]", raw_entities, re.DOTALL)
        entities = json.loads(m.group(0)) if m else []
        entities = [e for e in entities if isinstance(e, str) and e.strip()]

        if not entities:
            return {
                "recherches_effectuees": [],
                "faits_manquants": [],
                "contradictions": [],
                "divergences_de_cadrage": [],
                "impact": "faible",
                "fiabilite_sources": "Aucune source consultable (pas d'entit√©s d√©tect√©es).",
                "synthese": "Aucune entit√© d√©tect√©e ‚Äî enrichissement impossible."
            }

        # 2Ô∏è‚É£ Recherche web
        queries = []
        for ent in entities[:5]:
            queries += [f"{ent} actualit√©", f"{ent} controverse", f"{ent} critiques"]
        print("üåç Recherche web sur :", entities)
        recherches = search_web_results(queries, per_query=4)

        # 3Ô∏è‚É£ Synth√®se IA
        synth_prompt = f"""
        Compare le texte suivant avec les sources ci-dessous :
        - Identifie les faits manquants, contradictions et divergences de cadrage.
        R√©ponds uniquement en JSON :
        {{
          "faits_manquants": [{{"description": "...", "source": "...", "url": "..."}}],
          "contradictions": [{{"affirmation_du_texte": "...", "correction_ou_nuance": "...", "source": "...", "url": "..."}}],
          "divergences_de_cadrage": [{{"resume": "...", "impact": "..."}}],
          "impact": "<faible|moyen|fort>",
          "fiabilite_sources": "<description>",
          "synthese": "<r√©sum√© journalistique clair>"
        }}

        TEXTE :
        {text}

        SOURCES :
        {json.dumps(recherches, ensure_ascii=False, indent=2)}
        """
        synth_resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Tu es un fact-checker journalistique neutre et explicatif."},
                {"role": "user", "content": synth_prompt}
            ],
            temperature=0.3
        )
        content = synth_resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", content, re.DOTALL)
        result = json.loads(m.group(0)) if m else {}
        result["recherches_effectuees"] = recherches
        return result

    except Exception as e:
        print("‚ö†Ô∏è web_context_research failed:", e)
        return {
            "recherches_effectuees": [],
            "faits_manquants": [],
            "contradictions": [],
            "divergences_de_cadrage": [],
            "impact": "faible",
            "fiabilite_sources": "Recherche contextuelle non disponible.",
            "synthese": "Recherche contextuelle non disponible."
        }


# ======================================================
# üß© Route principale : analyse
# ======================================================
@app.route("/analyze", methods=["POST", "OPTIONS"])
def analyze():
    if request.method == "OPTIONS":
        return ("", 204)

    payload = request.get_json(silent=True) or {}
    text = (payload.get("text") or "").strip()
    if not text:
        return jsonify({"error": "Aucun texte re√ßu"}), 400

    # üîó Extraction d‚ÄôURL via Trafilatura (si activ√©e)
    if ENABLE_URL_EXTRACT and re.match(r"^https?://", text):
        try:
            import trafilatura
            fetched = trafilatura.extract(trafilatura.fetch_url(text)) or ""
            if len(fetched.strip()) >= 300:
                text = fetched.strip()[:8000]
                print(f"‚úÖ Trafilatura OK (len={len(text)})")
            else:
                print("‚ö†Ô∏è Extraction trop courte, texte brut conserv√©.")
        except Exception as e:
            print("‚ö†Ô∏è Trafilatura indisponible :", e)

    # Tronquage protecteur
    MAX_LEN = 8000
    texte_tronque = len(text) > MAX_LEN
    original_length = len(text)
    if texte_tronque:
        text = text[:MAX_LEN] + " [...] (texte tronqu√© pour analyse)"

    # ======================================================
    # üß© √âtape 1 ‚Äî Pr√©-analyse de type de texte (faits/opinions/autres)
    # ======================================================
    try:
        pre_prompt = f"""
        Classe le texte selon 3 cat√©gories :
        - FAITS (affirmations v√©rifiables)
        - OPINIONS (jugements ou interpr√©tations)
        - AUTRES (ironie, satire, po√©sie, r√©cit, etc.)

        Retourne un JSON au format :
        {{
          "faits": <int>,
          "opinions": <int>,
          "autres": <int>
        }}
        Texte :
        {text[:2000]}
        """
        pre_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un linguiste qui cat√©gorise les phrases d'un texte."},
                {"role": "user", "content": pre_prompt}
            ],
            temperature=0
        )
        raw_content = pre_resp.choices[0].message.content.strip()
        # Parsing JSON robuste avec regex
        try:
            fact_mix = json.loads(raw_content)
        except json.JSONDecodeError:
            # Tenter d'extraire le JSON du texte
            m = re.search(r"\{.*\}", raw_content, re.DOTALL)
            if m:
                fact_mix = json.loads(m.group(0))
            else:
                raise
    except Exception as e:
        print("‚ö†Ô∏è Erreur pr√©-analyse :", e)
        fact_mix = {"faits": 0, "opinions": 0, "autres": 0}

    total = sum(fact_mix.values()) or 1
    densite_faits = int((fact_mix["faits"] / total) * 100)
    type_texte = (
        "Principalement factuel" if densite_faits > 60 else
        "Opinion ou analyse" if fact_mix["opinions"] > 40 else
        "Autre (narratif, satirique‚Ä¶)"
    )

    # ======================================================
    # üåç √âtape interm√©diaire : Recherche Web enrichie
    #    (entit√©s ‚Üí recherche ‚Üí faits manquants / contradictions / impact)
    # ======================================================
    
    web_info = web_context_research(text) if ENABLE_CONTEXT_BOX else {
        "recherches_effectuees": [],
        "faits_manquants": [],
        "contradictions": [],
        "impact": "faible",
        "fiabilite_sources": "Contexte non activ√©.",
        "synthese": "Contexte non activ√©."
    }

    # ======================================================
    # üß† √âtape 3 ‚Äî Analyse principale compl√®te
    # ======================================================
    # ======================================================
    # üß† √âtape 3 ‚Äî Nouveau pipeline structur√© (analyse compl√®te)
    # ======================================================

    try:
        signal.alarm(60)

        # --- √âtape 0 : Message global per√ßu par le lecteur
        global_msg = extract_global_message(client, text)

        # --- √âtape 1 : R√©sum√© explicatif et extraction d‚Äôaffirmations v√©rifiables
        summary = summarize_text(client, text)


        # --- √âtape 2 : Recherche Web (sur entit√©s principales)
        entities = [f["texte"] for f in summary.get("faits", [])[:3]] if summary.get("faits") else []
        web_hits = search_web_results(entities)

        # --- √âtape 3 : Consolidation des faits trouv√©s
        web_facts = consolidate_web_facts(client, web_hits)

        # --- √âtape 4 : Comparaison entre le texte et le web
        diffs = compare_text_with_web(client, summary, web_facts)

        # --- Pond√©ration intelligente de l‚Äôimpact selon le message per√ßu
        if global_msg and "message_global" in global_msg:
            mg = global_msg["message_global"].lower()
            if "consensus" in mg or "apais√©" in mg or "unanimit√©" in mg:
                if len(diffs.get("faits_manquants", [])) > 0:
                    diffs["impact"] = "fort"
            elif "controverse" in mg or "division" in mg or "critique" in mg:
                diffs["impact"] = "moyen"

        
        # --- √âtape 5 : √âvaluation finale (notes sur 4 axes)
        evals = evaluate_text(client, summary, web_facts, diffs, global_msg)

        # Calcul du score global s√©par√© et d√©terministe
        try:
            axes_struct = evals.get("axes", {})
            final_score = compute_global_score(axes_struct, diffs.get("impact"), densite_faits)
        except Exception:
            final_score = 50

        # Remplir les champs de sortie normalis√©s
        evals["score_global"] = final_score
        evals["couleur_global"] = color_for(final_score)


        # --- √âtape 6 : Synth√®se finale √† partir des sous-notes
        evals["resume"] = synthesize_from_axes(client, evals)

        # --- Ajouts pour compatibilit√© avec l‚Äôancien front
        evals["message_global"] = global_msg
        evals["recherches_effectuees"] = web_hits
        evals["faits_web"] = web_facts
        evals["diffs"] = diffs
        evals["type_texte"] = type_texte
        evals["densite_faits"] = densite_faits
        evals["web_context"] = web_info
        evals["commentaire_web"] = formate_commentaires_web(web_info)


        # --- Pond√©ration douce du score global selon densit√© factuelle
        if "score_global" in evals:
            sg = int(evals["score_global"])
            if densite_faits > 60:
                sg = min(sg + 5, 100)
            elif densite_faits < 30:
                sg = max(sg - 5, 0)
            evals["score_global"] = sg
            evals["couleur_global"] = color_for(sg)

        # --- Ajout du log local (comme avant)
        try:
            log_item = {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "input_len": len(text),
                "type_texte": type_texte,
                "densite_faits": densite_faits,
                "score_global": evals.get("score_global"),
                "axes": evals.get("axes", {}),
                "resume": evals.get("resume"),
                "commentaire": evals.get("commentaire"),
            }
            with open("logs.jsonl", "a", encoding="utf-8") as f:
                f.write(json.dumps(log_item, ensure_ascii=False) + "\n")
        except Exception as e:
            print("‚ÑπÔ∏è √âchec √©criture logs.jsonl :", e)

        signal.alarm(0)
        print("‚úÖ Pipeline termin√©.")
        return jsonify(evals)

    except TimeoutError:
        return jsonify({"error": "Analyse trop longue (timeout)."}), 500
    except Exception as e:
        print("‚ùå Erreur pipeline :", e)
        return jsonify({"error": str(e)}), 500

        

# ======================================================
# üìú Historique des analyses
# ======================================================
@app.route("/logs", methods=["GET"])
def get_logs():
    """Retourne les 50 derni√®res analyses enregistr√©es."""
    logs = []
    try:
        if os.path.exists("logs.jsonl"):
            with open("logs.jsonl", "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        logs.append(json.loads(line))
                    except Exception:
                        continue
        logs = sorted(logs, key=lambda x: x.get("timestamp", ""), reverse=True)[:50]
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    return jsonify(logs)


# ======================================================
# Diagnostic / version
# ======================================================
@app.route("/version")
def version():
    return jsonify({"version": "De Facto v2.7-explicable-CSE", "status": "‚úÖ actif"})


# ======================================================
# Frontend (Replit uniquement)
# ======================================================
if os.getenv("REPL_ID"):
    @app.route("/")
    def serve_frontend():
        return send_from_directory(os.path.join(os.getcwd(), "frontend"), "index.html")

    @app.route("/<path:path>")
    def serve_static(path):
        frontend_path = os.path.join(os.getcwd(), "frontend")
        file_path = os.path.join(frontend_path, path)
        if os.path.exists(file_path):
            return send_from_directory(frontend_path, path)
        else:
            return send_from_directory(frontend_path, "index.html")


# ======================================================
# Run
# ======================================================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))
