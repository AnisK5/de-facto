# =============================================================
# üü¶ De Facto ‚Äî Backend p√©dagogique V2 (avec logs d√©taill√©s)
# =============================================================
# Objectif : que n'importe qui puisse suivre CE QUI SE PASSE
# √©tape par √©tape dans la console.
#
# üîÅ Pipeline :
# 1) Message global
# 2) R√©sum√© + faits + opinions
# 3) Entit√©s cl√©s
# 4) Recherche web (sources fiables)
# 5) Comparaison texte vs sources
# 6) √âvaluation des 4 axes
# 7) Synth√®se globale
# 8) Score final
# =============================================================

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from openai import OpenAI
import os, json, re, requests, time
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from typing import Dict, Any

# -------------------------------------------------------------
# üîµ 0) CONFIG GLOBALE & MODE DEBUG
# -------------------------------------------------------------

# ‚öôÔ∏è Activer / d√©sactiver les logs p√©dagogiques ici
DEBUG = True

# üé® Couleurs ANSI pour la console (juste pour le confort visuel)
C_RESET = "\033[0m"
C_BLUE = "\033[94m"
C_GREEN = "\033[92m"
C_YELLOW = "\033[93m"
C_MAGENTA = "\033[95m"
C_CYAN = "\033[96m"
C_BOLD = "\033[1m"

def log(title: str, message: str = "", color: str = C_CYAN, indent: int = 0):
    """Petit utilitaire pour afficher un message de log color√© et indent√©."""
    if not DEBUG:
        return
    prefix = " " * indent
    if message:
        print(f"{prefix}{color}{title}{C_RESET} {message}")
    else:
        print(f"{prefix}{color}{title}{C_RESET}")

def log_data(label: str, value: Any, indent: int = 4, color: str = C_YELLOW, max_len: int = 220):
    """Affiche une donn√©e interm√©diaire (tronqu√©e si elle est trop longue)."""
    if not DEBUG:
        return
    text = str(value)
    if len(text) > max_len:
        text = text[:max_len] + "‚Ä¶"
    prefix = " " * indent
    print(f"{prefix}{color}- {label}: {text}{C_RESET}")

class StepTimer:
    """Contexte pour mesurer le temps d‚Äôune √©tape."""
    def __init__(self, step_label: str):
        self.step_label = step_label
        self.start = None

    def __enter__(self):
        if DEBUG:
            self.start = time.time()
        return self

    def __exit__(self, exc_type, exc, tb):
        if DEBUG and self.start is not None:
            duration = time.time() - self.start
            log("‚è±Ô∏è Temps", f"{self.step_label} termin√© en {duration:.2f}s", C_GREEN, indent=4)

# -------------------------------------------------------------
# üîµ 1) CONFIG FLASK + OPENAI + SITES FIABLES
# -------------------------------------------------------------

app = Flask(__name__)
CORS(app)
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

ALLOWED_SITES = [
    "reuters.com", "apnews.com", "bbc.com",
    "lemonde.fr", "francetvinfo.fr",
    "lefigaro.fr", "liberation.fr", "leparisien.fr"
]

# -------------------------------------------------------------
# üîµ 2) UTILITAIRES G√âN√âRAUX
# -------------------------------------------------------------

def extract_json(text: str, fallback: dict):
    """
    üß© OpenAI renvoie parfois du texte qui contient du JSON au milieu.
    On essaie d'extraire le bloc { ... } et de le parser.
    """
    try:
        match = re.search(r"\{.*\}", text, re.DOTALL)
        return json.loads(match.group(0)) if match else fallback
    except Exception as e:
        log("‚ö†Ô∏è JSON ERROR", str(e), color=C_YELLOW, indent=4)
        return fallback

def color_for(score: int) -> str:
    """üñåÔ∏è Convertit une note en un emoji couleur (pour le front)."""
    if score >= 70:
        return "üü¢"
    if score >= 40:
        return "üü°"
    return "üî¥"

# -------------------------------------------------------------
# üîµ 3) STRUCTURES DE DONN√âES (Pydantic)
# -------------------------------------------------------------

class Axis(BaseModel):
    note: int = 50
    justification: str = ""
    citation: str = ""
    couleur: str = "‚ö™"

class Axes(BaseModel):
    fond: Dict[str, Axis]
    forme: Dict[str, Axis]

class AnalyzeRequest(BaseModel):
    text: str = Field(..., min_length=1)

class AnalyzeResponse(BaseModel):
    score_global: int
    couleur_global: str
    resume: str
    commentaire: str
    axes: Axes

    justesse: int
    completude: int
    ton: int
    sophismes: int

    confiance_analyse: int
    explication_confiance: str

# -------------------------------------------------------------
# üîµ 4) FONCTIONS D'ANALYSE (PIPELINE)
# -------------------------------------------------------------

# Activer l'extraction automatique des URL
ENABLE_URL_EXTRACT = True

# üü£ √âTAPE 0 ‚Äî EXTRACTION SIMPLE D'UN ARTICLE √Ä PARTIR D'UNE URL

def extract_article_from_url(url: str) -> str:
    """
    Version simple et robuste : d'abord Trafilatura,
    sinon fallback HTML ‚Üí texte.
    Retourne l'article propre ou "" si √©chec.
    """

    print("\nüîé [EXTRACT] Tentative extraction URL‚Ä¶")

    # 1) Trafilatura
    try:
        import trafilatura
        downloaded = trafilatura.fetch_url(url)
        extracted = trafilatura.extract(downloaded) if downloaded else ""
        if extracted and len(extracted) > 300:
            print(f"‚úÖ [EXTRACT] Trafilatura OK (len={len(extracted)})")
            return extracted
        print("‚ö†Ô∏è [EXTRACT] Trafilatura trop court ‚Üí fallback")
    except Exception as e:
        print("‚ö†Ô∏è [EXTRACT] Trafilatura erreur :", e)

    # 2) Fallback HTML ‚Üí texte
    try:
        import requests
        from bs4 import BeautifulSoup

        r = requests.get(url, timeout=6, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(r.text, "html.parser")

        # Supprime les √©l√©ments inutiles
        for tag in soup(["script", "style", "noscript", "footer", "header"]):
            tag.decompose()

        text = "\n".join(
            l.strip()
            for l in soup.get_text("\n").split("\n")
            if len(l.strip()) > 40
        )

        if len(text) > 300:
            print(f"‚úÖ [EXTRACT] Fallback OK (len={len(text)})")
            return text
        print("‚ùå [EXTRACT] Fallback trop court")
        return ""

    except Exception as e:
        print("‚ùå [EXTRACT] Fallback erreur :", e)
        return ""


# üü£ √âTAPE 1 ‚Äî Message global
def get_message_global(text: str):
    """
    1Ô∏è‚É£ On essaie de r√©sumer en UNE id√©e globale :
        - √Ä quoi sert l'article ?
        - Quel message principal il veut faire passer ?
    """
    with StepTimer("√âtape 1 - Message global"):
        log("[1/8] √âtape 1", "Analyse du message global‚Ä¶", C_BLUE)
        prompt = "Donne le message global en 3 lignes max. JSON {\"message\":\"...\"}"
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt + "\n\nTexte :\n" + text}]
        )
        data = extract_json(resp.choices[0].message.content, {"message": ""})
        log_data("Message global d√©tect√©", data.get("message", "‚Äî"))
        return data

# üü£ √âTAPE 2 ‚Äî R√©sum√© + faits + opinions
def summarize_facts(text: str):
    """
    2Ô∏è‚É£ On s√©pare :
        - ce qui est factuel (faits)
        - ce qui est subjectif (opinions)
    """
    with StepTimer("√âtape 2 - R√©sum√© + faits/opinions"):
        log("[2/8] √âtape 2", "R√©sum√© + extraction des faits et opinions‚Ä¶", C_BLUE)
        prompt = """
        Analyse le texte suivant.
        1) Fais un r√©sum√© court, et mettant en avant le message que veut faire passer l'article, ce qu'on est cens√©s retenir ou l'opinion qu'on est cens√©s se faire
        2) Liste les faits (chaque fait dans {"texte": "..."}).
        3) Liste les opinions (phrases subjectives).

        R√©ponds STRICTEMENT au format JSON :
        {
          "resume": "...",
          "faits": [{"texte":"..."}],
          "opinions": ["...", "..."]
        }
        """
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt + "\n\nTexte :\n" + text}]
        )
        data = extract_json(resp.choices[0].message.content,
                            {"resume": "", "faits": [], "opinions": []})

        log_data("R√©sum√©", data.get("resume", "‚Äî"))
        log_data("Nombre de faits d√©tect√©s", len(data.get("faits", [])))
        log_data("Nombre d'opinions d√©tect√©es", len(data.get("opinions", [])))

        # On affiche 1 ou 2 exemples pour p√©dagogie
        faits = data.get("faits", [])
        if faits:
            log_data("Exemple de fait", faits[0].get("texte", "‚Äî"), indent=6)
        opinions = data.get("opinions", [])
        if opinions:
            log_data("Exemple d'opinion", opinions[0], indent=6)

        return data

# üü£ √âTAPE 3 ‚Äî Entit√©s cl√©s
def extract_entities(text: str):
        """
        Analyse le texte et identifie les PRINCIPALES ASSERTIONS v√©rifiables qu‚Äôil contient.

        Une assertion = une phrase qui pr√©sente un fait, une implication, un pr√©suppos√© ou une cons√©quence suppos√©e vraie par le texte.

        Exemples :
        - ‚ÄúX est pressenti pour‚Ä¶‚Äù
        - ‚ÄúSelon le texte, Y pourrait permettre de‚Ä¶‚Äù
        - ‚ÄúIl est affirm√© que‚Ä¶‚Äù
        - ‚ÄúLe texte sugg√®re que‚Ä¶‚Äù

        R√®gles :
        - Extrais entre 3 et 6 assertions MAX.
        - Chaque assertion doit √™tre formul√©e clairement, comme une proposition factuelle qu‚Äôon peut v√©rifier sur des sources fiables.
        - Pas de r√©sum√©, pas de mots-cl√©s : uniquement des affirmations v√©rifiables.

        Format STRICT :
        [
          "assertion 1",
          "assertion 2",
          "assertion 3"
        ]
        """
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Extrais les principales assertions v√©rifiables du texte.\n\nTexte :\n" + text}]
        )
        data = extract_json(resp.choices[0].message.content, [])

        log_data("Entit√©s d√©tect√©es", data)

        return data

# üü£ √âTAPE 4 ‚Äî Recherche web
def search_web(entities: list):
    """
    4Ô∏è‚É£ √Ä partir des entit√©s, on interroge Google Custom Search
        sur une liste de m√©dias consid√©r√©s comme fiables.
    """
    with StepTimer("√âtape 4 - Recherche web"):
        log("[4/8] √âtape 4", "Recherche web sur des sources fiables‚Ä¶", C_BLUE)

        key = os.getenv("GOOGLE_CSE_API_KEY")
        cx = os.getenv("GOOGLE_CSE_CX")
        if not key or not cx:
            log("‚ö†Ô∏è GOOGLE_CSE", "Pas de cl√© API ou de CX configur√© ‚Üí recherche web d√©sactiv√©e.", C_YELLOW, indent=4)
            return []

        results = []
        for ent in entities[:3]:  # on limite √† 3 entit√©s pour ne pas exploser le quota
            query = f"{ent} ({' OR '.join(['site:' + s for s in ALLOWED_SITES])})"
            log_data("Requ√™te web", query, indent=6)

            r = requests.get(
                "https://www.googleapis.com/customsearch/v1",
                params={"key": key, "cx": cx, "q": query, "num": 4}
            )
            data = r.json()
            hits = [
                {"titre": i["title"], "snippet": i["snippet"], "url": i["link"]}
                for i in data.get("items", [])
            ]
            log_data(f"Nombre de sources pour ¬´ {ent} ¬ª", len(hits), indent=6)

            results.append({"entit√©": ent, "sources": hits})

        return results

# üü£ √âTAPE 5 ‚Äî Comparaison texte vs web
def compare_text_web(summary: dict, web_hits: list):
    """
    5Ô∏è‚É£ On compare :
        - ce que dit l'article (r√©sum√© + faits)
        - ce que disent les sources web
    pour rep√©rer :
        - faits manquants
        - contradictions
        - divergences
    """
    with StepTimer("√âtape 5 - Comparaison texte vs sources"):
        log("[5/8] √âtape 5", "Comparaison du texte avec les sources web‚Ä¶", C_BLUE)

        prompt = """
        Tu es un assistant qui compare un article avec des sources fiables.

        Voici :
        - summary: r√©sum√© de l'article + faits extraits
        - web_hits: extraits d'articles de presse fiables

        Identifie :
        - faits manquants (informations importantes pr√©sentes dans le web mais pas dans le texte)
        - contradictions (le texte dit X, les sources disent Y)
        - divergences (angles ou formulations tr√®s diff√©rentes)
        - impact global : "faible", "mod√©r√©", ou "fort"

        R√©ponds STRICTEMENT en JSON :
        {
          "faits_manquants": ["...", "..."],
          "contradictions": ["...", "..."],
          "divergences": ["...", "..."],
          "impact": "faible"
        }
        """

        # On envoie un contexte compact (on √©vite d'injecter tout brut)
        payload = {
            "summary": summary,
            "web_hits": web_hits,
        }

        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt},
                {"role": "user", "content": json.dumps(payload)}
            ]
        )
        data = extract_json(
            resp.choices[0].message.content,
            {"faits_manquants": [], "contradictions": [], "divergences": [], "impact": "faible"}
        )

        log_data("Impact global des diff√©rences", data.get("impact", "‚Äî"))
        log_data("Nb faits manquants", len(data.get("faits_manquants", [])))
        log_data("Nb contradictions", len(data.get("contradictions", [])))
        log_data("Nb divergences", len(data.get("divergences", [])))

        return data

# üü£ √âTAPE 6 ‚Äî √âvaluation des axes
def evaluate_axes(summary: dict, web_facts: list, diffs: dict, global_msg: dict):
    """
    6Ô∏è‚É£ √Ä partir de tout ce qu'on a vu, on attribue des notes :
        - fond / justesse
        - fond / compl√©tude
        - forme / ton
        - forme / sophismes
    """
    with StepTimer("√âtape 6 - √âvaluation des axes"):
        log("[6/8] √âtape 6", "√âvaluation des 4 axes‚Ä¶", C_BLUE)

        prompt = """
        Tu √©values la fiabilit√© d'un article selon 4 axes (0 √† 100).

        Contexte :
        - global_msg: message principal de l'article
        - summary: r√©sum√© + faits/opinions
        - web_facts: extraits d'articles fiables
        - diffs: analyse des faits manquants/contradictions/divergences

        Axes :
        - fond.justesse      : exactitude des faits
        - fond.completude    : article oublie-t-il des infos importantes ?
        - forme.ton          : neutralit√© vs biais
        - forme.sophismes    : qualit√© du raisonnement (peu / beaucoup de sophismes)

        R√©ponds STRICTEMENT au format JSON :
        {
          "axes": {
            "fond": {
              "justesse":  {"note": 0, "justification": "", "citation": ""},
              "completude":{"note": 0, "justification": "", "citation": ""}
            },
            "forme": {
              "ton":       {"note": 0, "justification": "", "citation": ""},
              "sophismes": {"note": 0, "justification": "", "citation": ""}
            }
          }
        }
        """

        payload = {
            "global_msg": global_msg,
            "summary": summary,
            "web_facts": web_facts,
            "diffs": diffs,
        }

        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": prompt},
                {"role": "user", "content": json.dumps(payload)}
            ]
        )

        data = extract_json(resp.choices[0].message.content, {"axes": {}})

        axes = data.get("axes", {})
        fond = axes.get("fond", {})
        forme = axes.get("forme", {})

        log_data("Note justesse", fond.get("justesse", {}).get("note", "‚Äî"))
        log_data("Note compl√©tude", fond.get("completude", {}).get("note", "‚Äî"))
        log_data("Note ton", forme.get("ton", {}).get("note", "‚Äî"))
        log_data("Note sophismes", forme.get("sophismes", {}).get("note", "‚Äî"))

        return data

# üü£ √âTAPE 7 ‚Äî Synth√®se globale
def build_synthesis(axes: dict):
    """
    7Ô∏è‚É£ On produit un texte synth√©tique qui explique le r√©sultat global
        (ce que le frontend affiche dans le gros encadr√©).
    """
    with StepTimer("√âtape 7 - Synth√®se"):
        log("[7/8] √âtape 7", "G√©n√©ration de la synth√®se globale‚Ä¶", C_BLUE)

        prompt = """
        √Ä partir des notes et justifications des axes, √©cris une synth√®se
        en 3 courts paragraphes, en fran√ßais, p√©dagogique et nuanc√©e.

        Ne fais pas de listes.
        """
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt},
                {"role": "user", "content": json.dumps(axes)}
            ]
        )
        text = resp.choices[0].message.content.strip()
        log_data("Synth√®se g√©n√©r√©e", text)
        return text

# üü£ √âTAPE 8 ‚Äî Score global
def compute_score(axes: dict) -> int:
    """
    8Ô∏è‚É£ √Ä partir des 4 notes, on calcule un score global pond√©r√©.
    Fond compte plus que forme.
    """
    with StepTimer("√âtape 8 - Score global"):
        log("[8/8] √âtape 8", "Calcul du score global‚Ä¶", C_BLUE)

        fond = axes.get("fond", {})
        forme = axes.get("forme", {})

        j = fond.get("justesse", {}).get("note", 0)
        c = fond.get("completude", {}).get("note", 0)
        t = forme.get("ton", {}).get("note", 0)
        s = forme.get("sophismes", {}).get("note", 0)

        score = int(0.4 * j + 0.3 * c + 0.15 * t + 0.15 * s)
        log_data("Score global calcul√©", score)
        return score

# -------------------------------------------------------------
# üîµ 5) ROUTE PRINCIPALE ‚Äî /analyze
# -------------------------------------------------------------

@app.route("/analyze", methods=["POST"])
def analyze():
    if DEBUG:
        print()
        log("===== üöÄ NOUVELLE ANALYSE LANC√âE =====", color=C_MAGENTA)

    try:
        payload = AnalyzeRequest(**request.json)
    except Exception as e:
        log("‚ùå ERREUR REQU√äTE", str(e), color=C_YELLOW)
        return jsonify({"error": "Requ√™te invalide"}), 400

    

    
    text = payload.text.strip()
    
    log_data("Texte re√ßu (d√©but)", text[:200] + ("‚Ä¶" if len(text) > 200 else ""), color=C_CYAN)


    # --------------------------------------------------
    # Si l'entr√©e est une URL ‚Üí on tente d'extraire l'article
    # --------------------------------------------------
    if ENABLE_URL_EXTRACT and re.match(r"^https?://", text):
        print("üåê [ANALYZE] URL d√©tect√©e :", text[:80], "...")
        extracted = extract_article_from_url(text)

        if extracted and len(extracted) > 300:
            print(f"üìù [ANALYZE] Article extrait (len={len(extracted)}) ‚Üí analyse OK\n")
            text = extracted[:8000]  # Limite s√©curit√©
        else:
            print("‚ùå [ANALYZE] Impossible d'extraire un article ‚Üí analyse probablement vide")
    
    
    # 1Ô∏è‚É£ ‚Üí 7Ô∏è‚É£ : pipeline d'analyse
    global_msg = get_message_global(text)
    summary = summarize_facts(text)
    entities = extract_entities(text)
    web_hits = search_web(entities)
    diffs = compare_text_web(summary, web_hits)
    evals = evaluate_axes(summary, web_hits, diffs, global_msg)
    axes = evals["axes"]

    synthese = build_synthesis(axes)
    score = compute_score(axes)

    # Ajout des couleurs pour chaque axe (pour le front)
    axes["fond"]["justesse"]["couleur"]   = color_for(axes["fond"]["justesse"]["note"])
    axes["fond"]["completude"]["couleur"] = color_for(axes["fond"]["completude"]["note"])
    axes["forme"]["ton"]["couleur"]       = color_for(axes["forme"]["ton"]["note"])
    axes["forme"]["sophismes"]["couleur"] = color_for(axes["forme"]["sophismes"]["note"])

    # Log final r√©cap
    log("‚úÖ ANALYSE TERMIN√âE", color=C_GREEN)
    log_data("Score global", score, indent=4, color=C_GREEN)
    log_data("Couleur globale", color_for(score), indent=4, color=C_GREEN)

    response = AnalyzeResponse(
        score_global=score,
        couleur_global=color_for(score),
        resume=synthese,
        commentaire=synthese,
        axes=Axes(fond=axes["fond"], forme=axes["forme"]),
        justesse=axes["fond"]["justesse"]["note"],
        completude=axes["fond"]["completude"]["note"],
        ton=axes["forme"]["ton"]["note"],
        sophismes=axes["forme"]["sophismes"]["note"],
        confiance_analyse=score,           # pour l'instant = m√™me valeur
        explication_confiance=""           # tu pourras remplir √ßa plus tard
    )

    return jsonify(response.model_dump())

# -------------------------------------------------------------
# üîµ 6) ROUTES POUR LE FRONTEND (fichiers statiques)
# -------------------------------------------------------------

@app.route("/")
def serve_frontend():
    frontend_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "frontend")
    return send_from_directory(frontend_dir, "index.html")

@app.route("/<path:path>")
def serve_static(path):
    frontend_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "frontend")
    file_path = os.path.join(frontend_dir, path)
    if os.path.exists(file_path):
        return send_from_directory(frontend_dir, path)
    return send_from_directory(frontend_dir, "index.html")

# -------------------------------------------------------------
# üîµ 7) LANCEMENT DU SERVEUR
# -------------------------------------------------------------

if __name__ == "__main__":
    log("üåê SERVEUR", "Lancement sur http://0.0.0.0:5000", C_MAGENTA)
    app.run(host="0.0.0.0", port=5000, debug=False)
