# ======================================================
# üîµ BLOC 1/6 ‚Äî IMPORTS + PYDANTIC + CONFIGURATION
# ======================================================

# ------------ IMPORTS G√âN√âRAUX ------------
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from openai import OpenAI
import os, signal, json, re, requests, urllib.parse, time
from datetime import datetime
from dotenv import load_dotenv

# Recherche web / threads
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# ------------ PYDANTIC ------------
from pydantic import BaseModel, Field, ValidationError
from typing import List, Dict, Optional, Any


# ======================================================
# üîß CONFIG FLASK & OPENAI
# ======================================================
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}}, supports_credentials=True)

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
ENABLE_URL_EXTRACT = True


# ======================================================
# üß© MOD√àLES PYDANTIC ‚Äî CONTRAT JSON GARANTI
# ======================================================

# ---------- UN ITEM D‚ÄôAXE ----------
class AxeItem(BaseModel):
    note: int = Field(default=50, ge=0, le=100)
    justification: str = ""
    exemple: str = ""
    effet: str = ""
    citation: str = ""
    couleur: str = "‚ö™"


# ---------- AXES FOND ----------
class AxesFond(BaseModel):
    justesse: AxeItem = AxeItem()
    completude: AxeItem = AxeItem()


# ---------- AXES FORME ----------
class AxesForme(BaseModel):
    ton: AxeItem = AxeItem()
    sophismes: AxeItem = AxeItem()


# ---------- STRUCTURE COMPL√àTE DES AXES ----------
class Axes(BaseModel):
    fond: AxesFond = AxesFond()
    forme: AxesForme = AxesForme()


# ---------- R√âPONSE FINALE (JSON RENVOY√â AU FRONTEND) ----------
class FinalResponse(BaseModel):
    score_global: int = 50
    couleur_global: str = "‚ö™"
    resume: str = "Analyse non disponible."
    commentaire: str = ""
    commentaire_web: str = ""

    # Pr√©-analyse
    densite_faits: int = 0
    type_texte: str = ""

    # Faits/opinions/message global
    message_global: Dict[str, Any] = {}
    recherches_effectuees: List[Any] = []
    faits_web: Dict[str, Any] = {}
    diffs: Dict[str, Any] = {}

    # Axes (structure propre)
    axes: Axes = Axes()

    # Compatibilit√© frontend
    justesse: int = 50
    completude: int = 50
    ton: int = 50
    sophismes: int = 50

    # D√©bogage
    web_context: Dict[str, Any] = {}

    # Confiance interne
    confiance_analyse: int = 70
    explication_confiance: str = "Analyse interne : coh√©rence moyenne entre les crit√®res."

# ======================================================
# üü¶ COMPL√âMENTS PYDANTIC MANQUANTS
# ======================================================

# Ce mod√®le d√©crit chaque entr√©e d‚Äôun axe en d√©tail.
class AxisDetail(BaseModel):
    note: int = Field(default=50, ge=0, le=100)
    justification: str = ""
    exemple: str = ""
    effet: str = ""
    citation: str = ""
    couleur: str = "‚ö™"


# Requ√™te envoy√©e par le frontend
class AnalyzeRequest(BaseModel):
    text: str = Field(..., min_length=1)


# R√©ponse compl√®te valid√©e envoy√©e au frontend
class AnalyzeResponse(BaseModel):
    score_global: int
    couleur_global: str
    resume: str
    axes: Axes

    justesse: int | None = None
    completude: int | None = None
    ton: int | None = None
    sophismes: int | None = None

    densite_faits: int = 0
    type_texte: str = ""
    message_global: dict = {}

    recherches_effectuees: list = []
    faits_web: dict = {}
    diffs: dict = {}
    web_context: dict = {}
    commentaire_web: str = ""
    commentaire: str = ""

    confiance_analyse: int = 70
    explication_confiance: str = ""


# ------------ TIMEOUT HANDLER ------------
def _timeout_handler(signum, frame):
    raise TimeoutError("Analyse trop longue (timeout Render/Replit).")

signal.signal(signal.SIGALRM, _timeout_handler)


# ------------ HELPER COULEUR ------------
def color_for(score: int) -> str:
    if score is None: return "‚ö™"
    if score >= 70: return "üü¢"
    if score >= 40: return "üü°"
    return "üî¥"




# ======================================================
# üîµ BLOC 2/6 ‚Äî RECHERCHE WEB + OUTILS D‚ÄôANALYSE
# ======================================================
# Ici :
#   - on d√©finit les sites autoris√©s
#   - on interroge Google CSE en parall√®le
#   - on formate le commentaire web
#   - on cr√©e les briques IA : r√©sum√©, message global,
#     consolidation web, comparaison, √©valuation, synth√®se.
# ======================================================

# ------------------------------------------------------
# 2.1 ‚Äî SITES AUTORIS√âS POUR LA RECHERCHE WEB
# ------------------------------------------------------
ALLOWED_SITES = [
    "reuters.com", "apnews.com", "bbc.com",
    "lemonde.fr", "francetvinfo.fr",
    "lefigaro.fr", "liberation.fr", "leparisien.fr"
]


# ------------------------------------------------------
# 2.2 ‚Äî RECHERCHE WEB (GOOGLE CSE)
# ------------------------------------------------------
def search_web_results(queries, per_query=5, pause=0.5):
    """
    Recherche Google Programmable Search (CSE) sur plusieurs requ√™tes.

    Entr√©e :
      - queries : liste de cha√Ænes, ex ["Macron actualit√©", "Union europ√©enne"]
    Sortie :
      - liste de blocs :
        [
          {
            "entit√©": "Macron actualit√©",
            "sources": [
              {"titre": "...", "snippet": "...", "url": "..."},
              ...
            ]
          },
          ...
        ]
    """

    api_key = os.getenv("GOOGLE_CSE_API_KEY")
    cx = os.getenv("GOOGLE_CSE_CX")

    if not api_key or not cx:
        print("‚ö†Ô∏è GOOGLE_CSE_API_KEY ou GOOGLE_CSE_CX manquant ‚Äî recherche d√©sactiv√©e.")
        return []

    all_hits = []      # Tous les r√©sultats agr√©g√©s
    seen = set()       # URLs d√©j√† vues (pour √©viter les doublons)
    seen_lock = Lock() # Verrou pour prot√©ger `seen` dans les threads

    # Sous-fonction ex√©cut√©e pour une requ√™te donn√©e
    def fetch(q):
        # Filtre sur la liste de sites autoris√©s
        site_filter = " OR ".join([f"site:{s}" for s in ALLOWED_SITES])
        full_q = f"{q} ({site_filter})"

        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": api_key,
            "cx": cx,
            "q": full_q,
            "num": per_query,
            "hl": "fr",
            "lr": "lang_fr",
            "safe": "off",
        }

        try:
            r = requests.get(url, params=params, timeout=8)
            if r.status_code != 200:
                return q, []

            data = r.json()
            results = []

            for item in (data.get("items", []) or []):
                link = item.get("link")
                if not link:
                    continue

                # D√©duplication multi-threads
                with seen_lock:
                    if link in seen:
                        continue
                    seen.add(link)

                results.append({
                    "titre": item.get("title"),
                    "snippet": item.get("snippet"),
                    "url": link
                })

            return q, results

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur recherche Google pour '{q}':", e)
            return q, []

    # Lancement en parall√®le (threads)
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(fetch, q) for q in queries]

        for fut in as_completed(futures):
            q, results = fut.result()
            if results:
                all_hits.append({"entit√©": q, "sources": results})

    return all_hits


# ------------------------------------------------------
# 2.3 ‚Äî COMMENTAIRE WEB LISIBLE √Ä PARTIR DE web_info
# ------------------------------------------------------
def formate_commentaires_web(web_info: dict) -> str:
    """
    Cr√©e un commentaire journalistique √† partir :
      - des faits manquants
      - des contradictions
      - des divergences de cadrage

    Ce texte est destin√© √† √™tre affich√© dans une "bo√Æte contexte"
    √† c√¥t√© de l‚Äôanalyse principale.
    """

    commentaires = []

    # 1Ô∏è‚É£ Contradictions : ton ‚Äúfact-check‚Äù nuanc√©
    for c in web_info.get("contradictions", []) or []:
        if isinstance(c, dict):
            commentaires.append(
                f"Selon {c.get('source', 'une source')}, "
                f"{(c.get('correction_ou_nuance') or '').strip()} "
                f"ce qui nuance l‚Äôaffirmation du texte "
                f"({(c.get('affirmation_du_texte') or '').strip()})."
            )
        elif isinstance(c, str):
            commentaires.append(c.strip())

    # 2Ô∏è‚É£ Faits manquants : ton ‚Äúanalyse critique‚Äù
    for f in web_info.get("faits_manquants", []) or []:
        if isinstance(f, dict):
            commentaires.append(
                f"Le texte n‚Äô√©voque pas {(f.get('description') or '').strip()} "
                f"(mentionn√© par {f.get('source', 'une autre source')}). "
                f"{(f.get('explication') or '').strip()}"
            )

    # 3Ô∏è‚É£ Divergences de cadrage : ton ‚Äúanalyse narrative‚Äù
    for d in web_info.get("divergences_de_cadrage", []) or []:
        if isinstance(d, dict):
            commentaires.append(
                f"Le cadrage diff√®re : {(d.get('resume') or '').strip()} "
                f"{(d.get('impact') or '').strip()}"
            )

    # 4Ô∏è‚É£ Synth√®se finale courte si disponible
    synth = web_info.get("synthese", "")
    if synth:
        commentaires.append((synth or "").strip())

    return " ".join(commentaires[:5]) or "Aucun √©cart majeur entre le texte et les sources consult√©es."


# ======================================================
# 2.4 ‚Äî BRIQUES IA : R√âSUM√â, MESSAGE GLOBAL, WEB FACTS
# ======================================================

# -------------------------
# 4.1 ‚Äî R√©sum√© + faits/opinions
# -------------------------
def summarize_text(client: OpenAI, text: str) -> dict:
    """
    √âtape 1 :
      - R√©sume le texte
      - Liste les faits (avec extraits)
      - Liste les opinions
    """

    prompt = f"""
    R√©sume le texte suivant de mani√®re neutre, puis liste :
    - Les faits (affirmations v√©rifiables)
    - Les opinions (jugements, interpr√©tations).

    Pour chaque fait, fournis un extrait (‚â§15 mots) prouvant d‚Äôo√π tu le tires.

    R√©ponds UNIQUEMENT en JSON :
    {{
      "resume": "...",
      "faits": [{{"texte": "...", "extrait_article": "..."}}],
      "opinions": ["...", "..."]
    }}

    Texte :
    {text[:4000]}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "Tu es un journaliste neutre. S√©pare faits/opinions avec extraits pr√©cis."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
        )

        raw = resp.choices[0].message.content.strip()
        match = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(match.group(0)) if match else {
            "resume": "",
            "faits": [],
            "opinions": []
        }

    except Exception as e:
        print("‚ö†Ô∏è summarize_text error:", e)
        return {"resume": "", "faits": [], "opinions": []}


# -------------------------
# 4.2 ‚Äî Message global per√ßu
# -------------------------
def extract_global_message(client: OpenAI, text: str) -> dict:
    """
    √âtape 0 :
      - message global retenu
      - ton
      - intention per√ßue
      - niveau de confiance
      - impression √©motionnelle
    """

    prompt = f"""
    Lis ce texte comme un lecteur moyen.
    D√©cris :
    1) Message global retenu
    2) Ton g√©n√©ral
    3) Intention per√ßue
    4) Niveau de confiance
    5) Impression √©motionnelle

    R√©ponds UNIQUEMENT en JSON :
    {{
      "message_global": "...",
      "ton_general": "...",
      "intention_per√ßue": "...",
      "niveau_de_confiance": "...",
      "resume_emotionnel": "..."
    }}

    Texte :
    {text[:4000]}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu d√©cris ce que retient un lecteur moyen."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.35,
        )
        raw = resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(m.group(0)) if m else {}

    except Exception as e:
        print("‚ö†Ô∏è extract_global_message error:", e)
        return {}


# -------------------------
# 4.3 ‚Äî Faits web consolid√©s
# -------------------------
def consolidate_web_facts(client: OpenAI, web_hits: list) -> dict:
    """
    √âtape 2 :
      - Convertit les r√©sultats web bruts ‚Üí liste de faits sourc√©s.
    """

    prompt = f"""
    Convertis ces extraits web en faits v√©rifiables et neutres.
    Pour chaque fait : indique la source, l‚ÄôURL et un extrait court.

    R√©ponds UNIQUEMENT en JSON :
    {{
      "faits_web": [
        {{"fait": "...", "source": "...", "url": "...", "extrait_source": "..."}}
      ]
    }}

    Extraits web :
    {json.dumps(web_hits, ensure_ascii=False, indent=2)}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu identifies des faits web neutres et sourc√©s."},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
        )

        raw = resp.choices[0].message.content.strip()
        match = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(match.group(0)) if match else {"faits_web": []}

    except Exception as e:
        print("‚ö†Ô∏è consolidate_web_facts error:", e)
        return {"faits_web": []}


# -------------------------
# 4.4 ‚Äî Comparaison texte vs web
# -------------------------
def compare_text_with_web(client: OpenAI, summary: dict, web_facts: dict) -> dict:
    """
    √âtape 3 :
      - Faits manquants
      - Contradictions
      - Divergences de cadrage
    """

    prompt = f"""
    Compare les faits du texte et les faits web.
    Identifie :
      - faits manquants
      - contradictions
      - divergences de cadrage

    Pour chaque cas, donne un extrait du texte + un extrait source.

    R√©ponds UNIQUEMENT en JSON :
    {{
      "faits_manquants": [...],
      "contradictions": [...],
      "divergences_de_cadrage": [...],
      "impact": "faible|moyen|fort"
    }}

    FAITS DU TEXTE :
    {json.dumps(summary, ensure_ascii=False, indent=2)}

    FAITS DU WEB :
    {json.dumps(web_facts, ensure_ascii=False, indent=2)}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu compares texte et sources web."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )

        raw = resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", raw, re.DOTALL)
        return json.loads(m.group(0)) if m else {
            "faits_manquants": [],
            "contradictions": [],
            "divergences_de_cadrage": [],
            "impact": "faible"
        }

    except Exception as e:
        print("‚ö†Ô∏è compare_text_with_web error:", e)
        return {
            "faits_manquants": [],
            "contradictions": [],
            "divergences_de_cadrage": [],
            "impact": "faible"
        }


# ======================================================
# 2.5 ‚Äî SCORE GLOBAL + RECHERCHE CONTEXTUELLE
# ======================================================

# -------------------------
# Score global (0‚Äì100)
# -------------------------
def compute_global_score(evals_axes: dict, diffs_impact: str, densite_faits: int) -> int:
    """
    Calcule un score global final (0‚Äì100) selon 4 pond√©rations :
      - Justesse       (40%)
      - Compl√©tude     (30%)
      - Ton            (15%)
      - Sophismes      (15%)

    Ajustements :
      - Impact 'fort' : -10 si Justesse < 60 ou Compl√©tude < 60
      - Impact 'moyen': -5  si Justesse < 60 ou Compl√©tude < 60
      - Densit√© factuelle : +5 si >60%, -5 si <30%
    """

    try:
        j = int(evals_axes["fond"]["justesse"]["note"])
        c = int(evals_axes["fond"]["completude"]["note"])
        t = int(evals_axes["forme"]["ton"]["note"])
        s = int(evals_axes["forme"]["sophismes"]["note"])
    except Exception:
        return 50  # S√©curit√© en cas de JSON partiel

    base = 0.4 * j + 0.3 * c + 0.15 * t + 0.15 * s

    impact = (diffs_impact or "faible").lower().strip()
    if (j < 60 or c < 60):
        if impact == "fort":
            base -= 10
        elif impact == "moyen":
            base -= 5

    if densite_faits > 60:
        base += 5
    elif densite_faits < 30:
        base -= 5

    return max(0, min(100, round(base)))


# -------------------------
# Recherche web contextuelle (NER ‚Üí web ‚Üí synth√®se)
# -------------------------
def web_context_research(text: str) -> dict:
    """
    √âtape d‚Äôenrichissement factuel :
      1) extraction d‚Äôentit√©s (NER)
      2) recherche web (Google CSE)
      3) synth√®se journalistique IA
    """

    try:
        # 1Ô∏è‚É£ Entit√©s NER
        ent_prompt = f"""
        Extrait les principales entit√©s (personnes, lieux, organisations, √©v√©nements)
        du texte suivant :
        {text[:2000]}

        R√©ponds UNIQUEMENT en JSON : ["entit√©1", "entit√©2", ...]
        """

        ent_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un extracteur d'entit√©s journalistiques (NER)."},
                {"role": "user", "content": ent_prompt}
            ],
            temperature=0,
        )

        raw_entities = ent_resp.choices[0].message.content.strip()
        m = re.search(r"\[.*\]", raw_entities, re.DOTALL)
        entities = json.loads(m.group(0)) if m else []

        entities = [
            e for e in entities
            if isinstance(e, str) and e.strip() and len(e.strip()) >= 2
        ]

        if not entities:
            return {
                "recherches_effectuees": [],
                "faits_manquants": [],
                "contradictions": [],
                "divergences_de_cadrage": [],
                "impact": "faible",
                "fiabilite_sources": "Aucune entit√© d√©tect√©e.",
                "synthese": "Impossible d‚Äôenrichir : aucune entit√© d√©tect√©e."
            }

        # 2Ô∏è‚É£ Recherche web
        queries = [f"{ent} actualit√©" for ent in entities[:3]]
        print("üåç Recherche web sur :", entities)
        recherches = search_web_results(queries, per_query=4)

        # 3Ô∏è‚É£ Synth√®se IA
        synth_prompt = f"""
        Compare le texte suivant avec les sources ci-dessous.
        Identifie :
        - faits manquants
        - contradictions
        - divergences de cadrage

        R√©ponds UNIQUEMENT en JSON :
        {{
          "faits_manquants": [...],
          "contradictions": [...],
          "divergences_de_cadrage": [...],
          "impact": "faible|moyen|fort",
          "fiabilite_sources": "...",
          "synthese": "..."
        }}

        TEXTE :
        {text}

        SOURCES :
        {json.dumps(recherches, ensure_ascii=False, indent=2)}
        """

        synth_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un fact-checker journalistique neutre."},
                {"role": "user", "content": synth_prompt}
            ],
            temperature=0.3,
        )

        content = synth_resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", content, re.DOTALL)
        result = json.loads(m.group(0)) if m else {}

        result["recherches_effectuees"] = recherches
        return result

    except Exception as e:
        print("‚ö†Ô∏è web_context_research failed:", e)
        return {
            "recherches_effectuees": [],
            "faits_manquants": [],
            "contradictions": [],
            "divergences_de_cadrage": [],
            "impact": "faible",
            "fiabilite_sources": "Erreur interne durant la recherche.",
            "synthese": "Recherche contextuelle indisponible."
        }


# ======================================================
# 2.6 ‚Äî SYNTH√àSE NARRATIVE & √âVALUATION PAR AXES
# ======================================================

def evaluate_text(client: OpenAI, summary: dict, web_facts: dict, diffs: dict, global_msg: Optional[dict] = None) -> dict:
    """
    √âtape 4 :
      - Note sur 4 axes :
          justesse, compl√©tude, ton, sophismes
      - Renvoie un JSON de la forme :
        { "axes": { "fond": {...}, "forme": {...} } }
    """

    msg_context = (global_msg or {}).get("message_global", "")

    prompt = f"""
    Tu √©values le texte sur 4 axes : justesse, compl√©tude, ton, rigueur argumentative.

    Structure OBLIGATOIRE :
    {{
      "axes": {{
        "fond": {{
          "justesse": {{
            "note": <0-100>,
            "justification": "...",
            "citation": "...",
            "exemple": "...",
            "effet": "..."
          }},
          "completude": {{
            "note": <0-100>,
            "justification": "...",
            "citation": "...",
            "exemple": "...",
            "effet": "..."
          }}
        }},
        "forme": {{
          "ton": {{
            "note": <0-100>,
            "justification": "...",
            "citation": "...",
            "exemple": "...",
            "effet": "..."
          }},
          "sophismes": {{
            "note": <0-100>,
            "justification": "...",
            "citation": "...",
            "exemple": "...",
            "effet": "..."
          }}
        }}
      }}
    }}

    R√®gles :
      - Donne un exemple pr√©cis pour chaque crit√®re.
      - Explique l‚Äôeffet sur le lecteur.
      - R√©ponds UNIQUEMENT avec du JSON.

    Contexte per√ßu : "{msg_context}"

    R√©sum√© :
    {json.dumps(summary, ensure_ascii=False, indent=2)}

    Faits web :
    {json.dumps(web_facts, ensure_ascii=False, indent=2)}

    Diff√©rences texte/web :
    {json.dumps(diffs, ensure_ascii=False, indent=2)}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Analyste p√©dagogique, concret, avec exemples."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.25,
        )

        raw = resp.choices[0].message.content.strip()
        m = re.search(r"\{.*\}", raw, re.DOTALL)
        parsed = json.loads(m.group(0)) if m else {"axes": {}}
        return parsed

    except Exception as e:
        print("‚ö†Ô∏è evaluate_text error:", e)
        return {"axes": {}}


def synthesize_from_axes(client: OpenAI, evaluation: dict) -> str:
    """
    √âtape 5 :
      - 3 paragraphes :
          1) Ce que le texte fait croire
          2) Ce qui manque / simplifie
          3) Effet global sur la compr√©hension
      - Jamais de score dans la synth√®se.
    """

    prompt = f"""
    √âcris une synth√®se en 3 blocs :
    1) Ce que le texte fait croire (message + ton + pr√©sentation)
    2) Ce qui manque ou simplifie (exemples + effet lecteur)
    3) Effet global sur la compr√©hension

    Interdits :
      - aucune note ou score
      - pas de jargon

    Mati√®re :
    {json.dumps(evaluation, ensure_ascii=False, indent=2)}
    """

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un journaliste explicateur, clair et concret."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.35,
        )

        return resp.choices[0].message.content.strip()

    except Exception as e:
        print("‚ö†Ô∏è synthesize_from_axes error:", e)
        return "Synth√®se non disponible."




# ======================================================
# üîµ BLOC 3/6 ‚Äî ROUTE PRINCIPALE /analyze
# ======================================================
# Pipeline complet :
#   1) Pr√©paration du texte (URL, tronquage)
#   2) Pr√©-analyse (faits/opinions/autres)
#   3) Lancement parall√®le :
#        - extract_global_message
#        - summarize_text
#        - web_context_research
#   4) Consolidation :
#        - faits web
#        - comparaison texte ‚Üî web
#   5) √âvaluation (4 axes)
#   6) Score global + couleur
#   7) Synth√®se narrative
#   8) Construction de la r√©ponse pour le frontend
# ======================================================


@app.route("/analyze", methods=["POST", "OPTIONS"])
def analyze():
    # CORS preflight
    if request.method == "OPTIONS":
        return ("", 204)

    # --------------------------------------------------
    # 3.1 ‚Äî R√âCUP√âRATION & VALIDATION DE L‚ÄôENTR√âE
    # --------------------------------------------------
    payload = request.get_json(silent=True) or {}

    try:
        parsed = AnalyzeRequest(**payload)
    except ValidationError:
        return jsonify({"error": "Aucun texte re√ßu"}), 400

    text = (parsed.text or "").strip()
    if not text:
        return jsonify({"error": "Aucun texte re√ßu"}), 400

    # --------------------------------------------------
    # 3.2 ‚Äî EXTRACTION D‚ÄôURL VIA TRAFILATURA (si activ√©e)
    # --------------------------------------------------
    if ENABLE_URL_EXTRACT and re.match(r"^https?://", text):
        try:
            import trafilatura

            downloaded = trafilatura.fetch_url(text)
            fetched = trafilatura.extract(downloaded) or ""
            if len(fetched.strip()) >= 300:
                text = fetched.strip()[:8000]
                print(f"‚úÖ Trafilatura OK (len={len(text)})")
            else:
                print("‚ö†Ô∏è Extraction trop courte ‚Üí texte brut conserv√©.")
        except Exception as e:
            print("‚ö†Ô∏è Trafilatura indisponible :", e)

    # --------------------------------------------------
    # 3.3 ‚Äî TRONQUAGE DE S√âCURIT√â (taille max)
    # --------------------------------------------------
    MAX_LEN = 8000
    if len(text) > MAX_LEN:
        text = text[:MAX_LEN] + " [‚Ä¶] (tronqu√© pour analyse)"

    # --------------------------------------------------
    # 3.4 ‚Äî PR√â-ANALYSE (densit√© factuelle)
    # --------------------------------------------------
    try:
        pre_prompt = f"""
        Classe le texte selon 3 cat√©gories :
        - FAITS (affirmations v√©rifiables)
        - OPINIONS (jugements)
        - AUTRES (r√©cit, humour, etc.)

        R√©ponds uniquement en JSON :
        {{
          "faits": <int>,
          "opinions": <int>,
          "autres": <int>
        }}

        Texte :
        {text[:2000]}
        """

        pre_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "Tu es un linguiste qui classe les phrases.",
                },
                {"role": "user", "content": pre_prompt},
            ],
            temperature=0,
        )
        raw = pre_resp.choices[0].message.content.strip()
        try:
            fact_mix = json.loads(raw)
        except json.JSONDecodeError:
            m = re.search(r"\{.*\}", raw, re.DOTALL)
            fact_mix = json.loads(m.group(0)) if m else {
                "faits": 0,
                "opinions": 0,
                "autres": 0,
            }

    except Exception as e:
        print("‚ö†Ô∏è Erreur pr√©-analyse :", e)
        fact_mix = {"faits": 0, "opinions": 0, "autres": 0}

    total = sum(fact_mix.values()) or 1
    densite_faits = int((fact_mix["faits"] / total) * 100)

    type_texte = (
        "Principalement factuel" if densite_faits > 60 else
        "Opinion ou analyse" if fact_mix["opinions"] > 40 else
        "Autre (narratif, satirique‚Ä¶)"
    )

    # --------------------------------------------------
    # 3.5 ‚Äî PIPELINE PRINCIPAL EN PARALL√àLE
    # --------------------------------------------------
    try:
        signal.alarm(120)  # s√©curit√© anti-timeout

        with ThreadPoolExecutor(max_workers=3) as executor:
            f_msg = executor.submit(extract_global_message, client, text)
            f_sum = executor.submit(summarize_text, client, text)
            f_webc = executor.submit(web_context_research, text)

            global_msg = f_msg.result()
            summary = f_sum.result()
            web_info = f_webc.result()

        # --------------------------------------------------
        # 3.6 ‚Äî CONSOLIDATION WEB & COMPARAISON
        # --------------------------------------------------
        web_hits = web_info.get("recherches_effectuees", [])
        web_facts = consolidate_web_facts(client, web_hits)
        diffs = compare_text_with_web(client, summary, web_facts)

        # Ajuster l‚Äôimpact selon le message global per√ßu
        if global_msg and "message_global" in global_msg:
            mg = (global_msg.get("message_global") or "").lower()
            if any(w in mg for w in ("consensus", "unanimit√©", "apais√©")) and diffs.get("faits_manquants"):
                diffs["impact"] = "fort"
            elif any(w in mg for w in ("controverse", "critique", "division")):
                diffs["impact"] = "moyen"

        # --------------------------------------------------
        # 3.7 ‚Äî √âVALUATION PAR AXES (justesse, compl√©tude‚Ä¶)
        # --------------------------------------------------
        evals_axes_full = evaluate_text(client, summary, web_facts, diffs, global_msg)
        axes_struct = evals_axes_full.get("axes", {})

        # S√©curit√© : structure par d√©faut si l‚ÄôIA a rat√© le format
        axes_struct.setdefault("fond", {})
        axes_struct.setdefault("forme", {})


        # Valeur par d√©faut pour un axe si l'IA n'a pas retourn√© le bon format
        fallback = {
            "note": 50,
            "justification": "Analyse non disponible",
            "citation": "",
            "severity_for_reader": "moyenne"
        }

        axes_struct["fond"].setdefault("justesse", fallback.copy())
        axes_struct["fond"].setdefault("completude", fallback.copy())
        axes_struct["forme"].setdefault("ton", fallback.copy())
        axes_struct["forme"].setdefault("sophismes", fallback.copy())


        # --------------------------------------------------
        # 3.8 ‚Äî SCORE GLOBAL (avec densit√© factuelle)
        # --------------------------------------------------
        base_score = compute_global_score(
            axes_struct,
            diffs.get("impact"),
            densite_faits,
        )

        # Lissage selon densit√© factuelle
        score_global = base_score
        if densite_faits > 60:
            score_global = min(score_global + 5, 100)
        elif densite_faits < 30:
            score_global = max(score_global - 5, 0)

        # --------------------------------------------------
        # 3.9 ‚Äî COULEURS PAR AXE + PATCH COMPAT FRONTEND
        # --------------------------------------------------
        try:
            axes_struct["fond"]["justesse"]["couleur"] = color_for(
                axes_struct["fond"]["justesse"].get("note")
            )
            axes_struct["fond"]["completude"]["couleur"] = color_for(
                axes_struct["fond"]["completude"].get("note")
            )
            axes_struct["forme"]["ton"]["couleur"] = color_for(
                axes_struct["forme"]["ton"].get("note")
            )
            axes_struct["forme"]["sophismes"]["couleur"] = color_for(
                axes_struct["forme"]["sophismes"].get("note")
            )
        except Exception as e:
            print("‚ö†Ô∏è Impossible d‚Äôajouter les couleurs aux axes :", e)

        # Champs √† plat pour le radar du frontend (compat)
        justesse_note = axes_struct["fond"]["justesse"].get("note")
        completude_note = axes_struct["fond"]["completude"].get("note")
        ton_note = axes_struct["forme"]["ton"].get("note")
        sophismes_note = axes_struct["forme"]["sophismes"].get("note")

        # --------------------------------------------------
        # 3.10 ‚Äî SYNTH√àSE NARRATIVE (3 paragraphes)
        # --------------------------------------------------
        synth√®se = synthesize_from_axes(
            client,
            {
                "axes": axes_struct,
                "score_global": score_global,
                "densite_faits": densite_faits,
                "type_texte": type_texte,
                "message_global": global_msg,
            },
        )

        # --------------------------------------------------
        # 3.11 ‚Äî CONSTRUCTION DE LA R√âPONSE (backend ‚Üí frontend)
        # --------------------------------------------------
        response_payload = {
            # Score global + couleur
            "score_global": score_global,
            "couleur_global": color_for(score_global),

            # Synth√®se
            "resume": synth√®se,
            "commentaire": synth√®se,  # compat ancien frontend

            # Axes d√©taill√©s
            "axes": axes_struct,
            "justesse": justesse_note,
            "completude": completude_note,
            "ton": ton_note,
            "sophismes": sophismes_note,

            # M√©tadonn√©es de texte
            "densite_faits": densite_faits,
            "type_texte": type_texte,
            "message_global": global_msg,

            # Contexte web et commentaire associ√©
            "recherches_effectuees": web_hits,
            "faits_web": web_facts,
            "diffs": diffs,
            "web_context": web_info,
            "commentaire_web": formate_commentaires_web(web_info),

            # Confiance de l‚Äôanalyse (proxy : score global)
            "confiance_analyse": score_global,
            "explication_confiance": "Analyse interne : coh√©rence moyenne entre les crit√®res.",
        }

        # --------------------------------------------------
        # 3.12 ‚Äî LOGGING LOCAL (logs.jsonl)
        # --------------------------------------------------
        try:
            log_item = {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "input_len": len(text),
                "type_texte": type_texte,
                "densite_faits": densite_faits,
                "score_global": score_global,
                "axes": axes_struct,
                "resume": synth√®se,
            }
            with open("logs.jsonl", "a", encoding="utf-8") as f:
                f.write(json.dumps(log_item, ensure_ascii=False) + "\n")
        except Exception as e:
            print("‚ÑπÔ∏è √âchec √©criture logs.jsonl :", e)

        # Optionnel : valider la structure de sortie avec Pydantic
        # (s√©curit√© suppl√©mentaire, mais pas obligatoire)
        try:
            resp_model = AnalyzeResponse(
                score_global=score_global,
                couleur_global=color_for(score_global),
                resume=synth√®se,
                axes=Axes(
                    fond=AxesFond(
                        justesse=AxisDetail(**axes_struct["fond"]["justesse"]),
                        completude=AxisDetail(**axes_struct["fond"]["completude"]),
                    ),
                    forme=AxesForme(
                        ton=AxisDetail(**axes_struct["forme"]["ton"]),
                        sophismes=AxisDetail(**axes_struct["forme"]["sophismes"]),
                    ),
                ),
                densite_faits=densite_faits,
                type_texte=type_texte,
                message_global=global_msg,
                recherches_effectuees=web_hits,
                faits_web=web_facts,
                diffs=diffs,
                web_context=web_info,
                commentaire_web=response_payload["commentaire_web"],
                commentaire=response_payload["commentaire"],
                confiance_analyse=response_payload["confiance_analyse"],
                explication_confiance=response_payload["explication_confiance"],
            )
            # On retourne le dict valid√© (et compatible frontend)
            return jsonify(resp_model.model_dump())
        except Exception as e:
            # Si la validation Pydantic √©choue, on renvoie quand m√™me le dict brut
            print("‚ö†Ô∏è Validation Pydantic AnalyzeResponse √©chou√©e :", e)
            return jsonify(response_payload)

    except TimeoutError:
        return jsonify({"error": "Analyse trop longue (timeout)."}), 500

    except Exception as e:
        print("‚ùå Erreur pipeline analyze() :", e)
        return jsonify({"error": str(e)}), 500

    finally:
        signal.alarm(0)  # toujours d√©sarmer le timeout


# ======================================================
# üîµ BLOC 4/6 ‚Äî HISTORIQUE DES ANALYSES (/logs)
# ======================================================

@app.route("/logs", methods=["GET"])
def get_logs():
    """
    Retourne les 50 derni√®res analyses enregistr√©es dans logs.jsonl.
    Format : liste de JSON (timestamp, score, densit√© de faits, etc.)
    """
    logs = []

    try:
        if os.path.exists("logs.jsonl"):
            with open("logs.jsonl", "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        logs.append(json.loads(line))
                    except Exception:
                        continue  # ligne corrompue ignor√©e

        logs = sorted(
            logs,
            key=lambda x: x.get("timestamp", ""),
            reverse=True,
        )[:50]

    except Exception as e:
        return jsonify({"error": str(e)}), 500

    return jsonify(logs)


# ======================================================
# üîµ BLOC 5/6 ‚Äî DIAGNOSTIC /version
# ======================================================

@app.route("/version", methods=["GET"])
def version():
    """
    Endpoint de diagnostic.
    Permet de v√©rifier que l'API est vivante et d'afficher un label de version.
    """
    return jsonify({
        "version": "De Facto v2.8-explicable-CSE-pyramid-pydantic",
        "status": "‚úÖ actif"
    })


# ======================================================
# üîµ BLOC 6/6 ‚Äî FRONTEND (Replit) + LANCEMENT SERVEUR
# ======================================================

if os.getenv("REPL_ID"):
    @app.route("/")
    def serve_frontend():
        """Sert le fichier frontend/index.html comme page d'accueil en mode Replit."""
        return send_from_directory(
            os.path.join(os.getcwd(), "frontend"),
            "index.html"
        )

    @app.route("/<path:path>")
    def serve_static(path: str):
        """
        Sert les fichiers statiques du dossier frontend (JS, CSS, images).
        Si le fichier demand√© n'existe pas, on renvoie index.html
        pour laisser le frontend (ex: React) g√©rer le routage.
        """
        frontend_path = os.path.join(os.getcwd(), "frontend")
        file_path = os.path.join(frontend_path, path)

        if os.path.exists(file_path):
            return send_from_directory(frontend_path, path)
        else:
            return send_from_directory(frontend_path, "index.html")


if __name__ == "__main__":
    # Lancement du serveur Flask
    app.run(
        host="0.0.0.0",
        port=int(os.environ.get("PORT", 5000)),
    )
